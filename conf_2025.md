# Generic

* LASER: Attention with Exponential Transformation `Google` `UAustinTexas`
	> Tweak self-attention so larger gradient get propagated through the model. A simple proposal that works on top of both vanilla and flash attention.

* Triaging mammography with artificial intelligence: an implementation study `Breast Cancer Research and Treatment` `US`
	> Use triaging software to speed-up additional images and diagnostic procedure through a prioritized workflow stream.
	
* Welcome to the Era of Experience `Richard S. Sutton` `Alan` `Turning` `DeepMind` `CA` `GB` `UK`
	> Going beyond Human-supervised AI, into experience-supervsied AI. In the experience era, AI will recieve inputs from many modalities and sensors -- unlike LLMs. The AI models/agents will be supervised using streams of experience -- not input,output pairs. These streams will span long durations of experience, not just short snippets of interaction. These models/agents reward/loss function will come from the environment, not a human defined ground-truth output. These models/agents will plan and reason about the experience, in some latent space and not solely in human terms (language tokens).
	
# arXiv

* Scaling Language-Free Visual Representation Learning `FAIR` `NYU` `US`
	> Vision contrastive SSL pre-trained models (e.g., DINO) are competitive/superior to vision-language models (e.g., CLIP) at the right data and model scales. Masked Autoencoder methods (e.g., MAE) is competitive as well, but slightly inferior to contrastive SSL models. Web-scale data -- with text content -- boost SSL models in OCR and chart performance tasks. At the right data and model scale, the representation learned by vision only models becomes similar (increasingly aligned) with the representation learned by vision-language models.
	
# ICLR 

* Has the Deep Neural Network learned the Stochastic Process? An Evaluation Viewpoint `US` `WR`
	> Propose Expected Calibration Error (ECE) as an evlaution metric for DNNs trained on stochastic processes (e.g., forest fire, stock market).

* MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models `US` 
	> A new dataset that highlight limitations of medical multi-modal LLMs (MLLMs). Surprisingly, commerical generic MLLM beats medical models on this dataset. The dataset highlights medical MLLMs limitations when presented with nuanced questions -- outside the general medical knowledge domain.