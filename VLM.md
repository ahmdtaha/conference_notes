# VLM Review

## Architecture/Training Objectives

### 1. Contrastive Language Image Pre-training (CLIP) by OpenAI
Trains on image-text pairs crawled from internet. [arXiv](https://arxiv.org/abs/2103.00020)
![](./imgs/clip_openai.png)

### 2. A Large-scale ImaGe and Noisy-text embedding (ALIGN) by Google Research
Trains on _Noisy_ image-text pairs crawled from internet. [arXiv](https://arxiv.org/abs/2102.05918)

The _Noisy_ training datasets is the key difference between ALIGN and CLIP.

![](./imgs/align_google.png)

