* Exploring Simple Siamese Representation Learning **#arxiv2020**
* Dissecting Image Crops -- `PI_Reading_Grp` **#arxiv2020**
* Meta Pseudo Labels **#arxiv2020**
* Training data-efficient image transformers & distillation through attention -- `PI_Reading_Grp` :hash:industry :hash:FB **#arxiv2020**
	> Technicalities
* A Simple Semi-Supervised Learning Framework for Object Detection **#arxiv2020** :hash:industry :hash:Google Brain
* Localization Uncertainty Estimation for Anchor-Free Object Detection -- `Gaussian FCOS` **#arxiv2020**
* Are we done with ImageNet? **#arxiv2020**
* Talking-Heads Attention **#arxiv2020**
* Learned Initializations for Optimizing Coordinate-Based Neural Representations **#arxiv2020**
* Splitting Convolutional Neural Network Structures for Efficient Inference **#arxiv2020**
* Your Classifier Is Secretly An Energy Based Model And You Should Treat It Like One **#arxiv2020**
* Architecture Disentanglement for Deep Neural Networks **#arxiv2020**
* Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases **#arxiv2020**
* Supervised Contrastive Learning **#arxiv2020**
* Supermasks in superposition **#arxiv2020**
* Deep Adaptive Semantic Logic (DASL): Compiling Declarative Knowledge into Deep Neural Networks **#arxiv2020**
	> Interesting topic. Should read more about it.
* Dynamic Sampling for Deep Metric Learning **#arxiv2020**
* Watching the World Go By: Representation Learning from Unlabeled Videos **#arxiv2020**
* State-of-Art-Reviewing: A Radical Proposal to Improve Scientific Publication **#arxiv2020**
* A Simple Framework for Contrastive Learning of Visual Representations **#arxiv2020**
	> Looks simple but use a batch_size=8192, trained for 100 epochs on imagenet.
* Adaptive Self-Training For Few-Shot Neural Sequence Labeling **#arxiv2020**
* Stabilizing the Lottery Ticket Hypothesis **#arxiv2019**
* Sparse Transfer Learning via Winning Lottery Tickets **#arxiv2019**
* INTRIGUING PROPERTIES OF LEARNED REPRESENTATIONS **openreview2019-ICLR**
* Unsupervised Representation Learning by Predicting Image Rotations **arxiv2018**
* Self-EMD: Self-Supervised Object Detection without ImageNet **#arxiv2020**
* MammoGANesis: Controlled Generation of High-Resolution Mammograms for Radiology Education `arXiv` `mammogram` `Medical`
* Contrastive Learning of Medical Visual Representations from Paired Images and Text `Medical`
* TResNet: High Performance GPU-Dedicated Architecture `Technicalities`
* RP2K: A Large-Scale Retail Product Dataset for Fine-Grained Image Classification 
	> 14,368 high-resolution shelf images, on average, 37.1 objects per image, resulting in 533,633 images of individual objects. Each individual object image represents a product from in total of 2000 SKUs