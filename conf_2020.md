* Reinforcement Learning with Videos: Combining Offline Observations with Interaction -- `PI_Reading_Grp` **#corl2020**
* Learning Hyperbolic Representations For Un- Supervised 3D Segmentation **#arXiv2020**
* ResNeSt: Split-Attention Networks **#arXiv2020**
* Eta-Dataset: A Dataset Of Datasets For Learning To Learn From Few Examples **#iclr2020**
* Fast is better than free: Revisiting adversarial training **#iclr2020**
* On the Relationship between Self-Attention and Convolutional Layers **#iclr2020**
* Comparing Rewinding and Fine-tuning in Neural Network Pruning **#iclr2020** (I read this on 26 Dec 2020)
* Linear mode connectivity and the lottery ticket hypothesis **#icml2020**
* Stable Prediction with Model Misspecification and Agnostic Distribution Shift **#aaai2020**
	> Watch this video first https://www.youtube.com/watch?v=wCJ8I-MtJdQ
* The Lottery Ticket Hypothesis for Pre-trained BERT Networks **#nips2020**
* Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection `NIPS`
* Unsupervised learning of visual features by contrasting cluster assignments `SSL` `NIPS` `Facebook` `SwAV`
* Retrospective Loss: Looking Back to Improve Training of Deep Neural Networks  **#kdd2020**
* tree-cnn: a hierarchical deep convolutional neural network for incremental learning **#NeuralNetworks2020**
* FCOS: A Simple and Strong Anchor-free Object Detector **#pami2020**
* Curriculum by Smoothing -- `PI_Reading_Grp` **#nips2020**
* Contrastive Learning with Adversarial Examples **#nips2020**
* Stochastic Optimization with Laggard Data Pipelines **#nips2020** -- `Nice` 
* The origins and prevalence of texture bias in convolutional neural networks **#nips2020**
* FixMatch: Simplifying Semi Supervised learning with consistency and confidence -- `PI_Reading_Grp` **#nips2020**
* Big Self Supervised Models are Strong Semi Supervised learners -- `PI_Reading_Grp` **#nips2020**
* What makes for good views for contrastive learning **#nips2020** `Nice` 
* Structured Convolutions for Efficient Neural Network Design **#nips2020**
	> Tensor decomposition. Not sure why flops are not reported!
* LoCo: Local Contrastive Representation Learning **#nips2020**
* Auxiliary Task Reweighting for Minimum-data Learning **#nips2020**
	> Well written paper
* Bootstrap Your Own Latent A New Approach to Self-Supervised Learning **#nips2020**
* Understanding the Role of Individual Units in a Deep Neural Network **National Academy of Sciences2020**
* Learning to combine Top-down to Buttom-up signals **#icml2020**
* Revisiting Training Strategies and Generalization Performance in Deep Metric Learning **#icml2020**
* Using Deep Learning to Accelerate Knee MRI at 3 T: Results of an Interchangeability Study -- `NYU` **American Journal of Roentgenology**
* International evaluation of an AI system for breast cancer screening -- `DeepMind` **Nature**
* A Hypersensitive Breast Cancer Detector -- `WR-AI` **SPIE Medical Imaging 2020**
* Adaptation of a deep learning malignancy model from full-field digital mammography to digital breast tomosynthesis -- `WR-AI` **SPIE Medical Imaging 2020**
* Effect of artificial intelligence-based triaging of breast cancer screening mammograms on cancer detection and radiologist workload: a retrospective simulation study -- `WR-AI` **The Lancet 2020**
* A Multi-site Study of a Breast Density Deep Learning Model for Full-field Digital Mammography Images and Synthetic Mammography Images -- `WR-AI` **Radiology: Artificial IntelligenceVol 2020**
* MommiNet: Mammographic Multi-View Mass Identification Networks -- `WR-AI` **MICCAI2020**
* Performance deterioration of deep neural networks for lesion classification in mammography due to distribution shift: an analysis based on artificially created distribution shift **SPIE2020** `Nice paper`
* LS-SSDD-v1.0: A Deep Learning Dataset Dedicated to Small Ship Detection from Large-Scale Sentinel-1 SAR Images **Remote Sensing**
