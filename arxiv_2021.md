* Learning Transferable Visual Models From Natural Language Supervision **#openai2021**
* LambdaNetworks: Modeling long-range Interactions without Attention **#openreview2021** -- Seems like a good idea, poorly written.
* Re-labeling ImageNet:from Single to Multi-Labels, from Global to Localized Labels **#arXiv2021** -- `PI_Reading_Grp`
* Bottleneck Transformers for Visual Recognition **#arXiv2021** -- `PI_Reading_Grp` Technicalities
* Towards General Purpose Vision Systems **#arXiv2021** -- `PI_arXiv_Grp` Technicalities
* Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision **#arXiv2021** -- `PI_arXiv_Grp` Technicalities
* MLP-Mixer: An all-MLP Architecture for Vision **#arXiv2021** `Arch_Design`
* FNet: Mixing Tokens with Fourier Transforms **#arXiv2021** `Arch_Design`
* Learning Open-World Object Proposals without Learning to Classify **#arXiv2021** `Detection`
* nnFormer: Interleaved Transformer for Volumetric Segmentation **#arXiv2021** `Detection`
* Early Convolutions Help Transformers See Better **#arXiv2021** `Transformer`
* Efficient Training of Visual Transformers with Small-Size Datasets **#arXiv2021** `Transformer`
* VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning **#arXiv2021** `SSL`
* Swin transformer: Hierarchical vision transformer using shifted windows **#arXiv2021** `Transformer`

