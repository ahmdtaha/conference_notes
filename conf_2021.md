### ICCV 2021

* Is it Time to Replace CNNs with Transformers for Medical Images? `Workshop`
* DINO: Emerging properties in self-supervised vision transformers. `Facebook` 
	> Revisited
* End-to-End Semi-Supervised Object Detection with Soft Teacher. `Microsoft` 
* Tokens-to-Token ViT: Training Vision Transformers From Scratch on ImageNet
	> propose overlapping token -- poorly written
* Pyramid vision transformer: A versatile backbone for dense prediction without convolutions -- `Technicalities` `ViT` `Det`
* Big Self-Supervised Models Advance Medical Image Classifications `Medical` `Google` `Nice`
	> Use ImageNet as initialization before self-supervised learning to speed up convergence. Use positive crops for multi-view images. partial (light-weight) augmentationis enough if positive pairs are sampled efficiently (Tab. B.2). SSL help with model robustness (Fig. 4).
* Divide and Contrast: Self-supervised Learning from Uncurated Data `DeepMind` `SSL`
* With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations `SSL` `DeepMind` `Google`
* Dynamic detr: End-to-end object detection with dynamic attention `Microsoft` `Technicalities`
	> Same team and ideas from Dynamic Head (CVPR 2021)
* Visual Transformers: Where Do Transformers Really Belong in Vision Models? `Facebook`	> Tricky	
* Going deeper with Image Transformers `Facebook` `Deep` `Transformers`
* Rethinking imagenet pre-training `FAIR` `Nice` `Detection`
* LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference `Transformers` `Facebook`
* Co-Scale Conv-Attentional Image Transformers `Transformers` `detection` `Oral`
* Detail Me More: Improving GANâ€™s photo-realism of complex scenes `GANs` `AMZN`
* When do GANs replicate? On the choice of dataset size `GANs` `AMZN`
* Multiscale Vision Transformers `FAIR` `Video`
* CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification `MvT` `IBM`
	> Multiscale vision transformer evaluated using classification task only!
* Pretrained ViTs Yield Versatile Representations For Medical Images `Workshop` `Medical` `ViTs`
	> ViTs attention is remarkable
* Instances as Queries `Segmentation` `Detection` `Nice`
	> Use the same query objects (as in DETR) inside DynamicConv to generate object masks. one query -> one object -> mask correspondence. Well Written
* Effectively leveraging attributes for visual similarity.
	> conditional metric learning done using joint image-pair feature embedding.
* Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models
	> Composed image retrieval using pre-trained VLP models.
* An Empirical Study of Training Self-Supervised Vision Transformers `Meta` `Oral`
	> Moco v3 drops key queue, bz=4096 seems enough! Besides backbone+projection, a prediction MLP is added. AdamW seems more stable compared to LAMB. Random patch projection is enough to learn a good representation even without positional embedding. 

### WACV 2021
* ResNet or DenseNet? Introducing Dense Shortcuts to ResNet -- `Technicalities`

### MICCAI 2021

* CoTr: Efficiently Bridging CNN and Transformer for 3D Medical Image Segmentation
	> Transformers + Medical Images


### ICLR 2021
* Concept Learners For Few-Shot Learning 
* SEED: Self-supervised Distillation For Visual Representation
* Unbiased Teacher for Semi-Supervised Object Detection
* Rethinking Attention With Performers `Google`
* Sharpness-Aware Minimization For Efficiently Improving Generalization -- `WR-AI` `Google`
* Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning 
	> Did it before it was cool
* What Should Not Be Contrastive In Contrastive Learning
	> Brute Force	
* Grokking: Generalization beyond Overfitting on small algorithmic datasets `Workshop` 
* Deformable DETR: Deformable Transformers for End-to-End Object Detection `Oral`
	> Replace vanilla self-attention in DETR with deformable conv to speed up convergence and reduce computational complexity.
* NFNets: High-Performance Large-Scale Image Recognition Without Normalization `DeepMind`
* An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale `PI_Reading_Grp` `Google`
* On the geometry of generalization and memorization in deep neural networks `Nice` `Intel`
	> explain double-descent, early layers generalize while late layers memorize, lack of gradient magnitude differences between early and late layers
* Does enhanced shape bias improve neural network robustness to common corruptions? `Nice`
	> Nice analysis; style augmentation improves robustness corruptions, while enhancing shape bias makes networks more vulnerable


	
### Generic 2021
* Why AI is Harder Than We Think `arXiv`
* ClipCap: CLIP Prefix for Image Captioning `arXiv`
	> Combine CLIP model and a LLM to train a light-weight captioning model.
* Extracting Training Data from Large Language Models `usenix` `LLM`
* How Much Can CLIP Benefit Vision-and-Language Tasks? `arXiv` `CLIP`
* Evaluating Large Language Models Trained on Code `arXiv` `OpenAI`
* Vision Transformers with Patch Diversification `arXiv` `Transformers` `Nice`
	> Apply patch-level regularization.
* MetaFormer is Actually What You Need for Vision `arXiv` `Transformers`
	> Probably wrong conclusion
* RegNet: Self-Regulated Network for Image Classification `arXiv` `Architecture`
* RoFormer: Enhanced Transformer with Rotary Position Embedding `arXiv` `Transformers`
* TransAttUnet: Multi-level attention- guided u-net with transformer for medical image segmentation `arXiv` `Transformers` `Medical` 
* Florence: A New Foundation Model for Computer Vision `arXiv`
* Stochastic Training is Not Necessary for Generalization `arXiv`
* TransClaw U-Net: Claw u-net with transformers for medical image segmentation. `arXiv` `Transformers`  `Medical` 
* TransUNet: Transformers make strong encoders for medical image segmentation `arXiv` `Transformers`  `Medical` 
* Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation `Transformers`  `Medical` 
* TransFuse: Fusing transformers and cnns for medical image segmentation `MICCAI` `Transformers`
* Convolution-free medical image segmentation using transformers `MICCAI` `Transformers`
* Medical Transformer: Gated Axial-Attention for Medical Image Segmentation `MICCAI` `Transformers`
* Multi-view Analysis of Unregistered Medical Images Using Cross-View Transformers `MICCAI` `Transformers`
* Token Pooling In Vision Transformers `arXiv` `Transformers` 
* MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer `arXiv` `Transformers`
* LocalViT: Bringing Locality to Vision Transformers `arXiv` `Transformers`
	> Encode location using DW Conv. Important for early layers
* Not All Knowledge Is Created Equal `arXiv` 
* Patches are all you need `OpenReview` 
	> Smaller patches boost performance
* Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity `arXiv` `DETR` 
* When Vision Transformers Outperform Resnets Without Pre-Training Or Strong Data Augmentations `arXiv` `Transformers` 
* Do Vision Transformers See Like Convolutional Neural Networks? `arXiv` `Transformers` 
* CvT: Introducing convolutions to vision transformers `arXiv``Transformers` 
* Augmenting Convolutional networks with attention-based aggregation `Meta` `arXiv`
	> Seems to have stability issues 
* SLIP: Self-supervision meets Language-Image Pre-training `Meta` `arXiv`
* Object-aware Contrastive Learning for Debiased Scene Representation `NIPS` 
* Unsupervised object-level representation learning from scene images `NIPS` 
	> Use ssl on image-pretraining to retrieval KNN for images. Perform selective search to extract regions from every image. Match regions from one images to regions from a paired (KNN) images. Perform ssl on region-pretraining.
* Intriguing Properties of Vision Transformers `NIPS` `Nice` `Google`
	> ViTs are neither shape nor textured biased. They just less biased towards local textures. There is a shape-bias vs. robustness!
* XCiT: Cross-Covariance Image Transformers `NIPS` `Faceboook`
	> Replace Attention Kernel (Gram) with Co-variance matrix. Mixing channels instead of mixing tokens. "communication between patches is only implicit through the shared statistics".
* CoAtNet: Marrying Convolution and Attention for All Data Sizes `NIPS`
* Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers `NIPS` `RNNs`
* Twins: Revisiting the Design of Spatial Attention in Vision Transformers `NIPS` `ViT` `PvT` `MvT`
	> Use conditional position encoding (CPE) instead of PE + Subsample with Conv. Twins-PCPVT-L seems promising. 
* Overinterpretation reveals image classification model pathologies `Nice` `NIPS` 
* Does Knowledge Distillation Really Work? `NIPS`
* Focal attention for long-range interactions in vision transformers. `Nice` `MSR`
	> Dedicated arch for object detection. Pyramid-ViT with better performance but more compute (FLops).
* Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks `Nice` `NIPS` 
	> Replace feed-forward stages inside ResNet with a single recurrent stage.
* Learning Debiased Representation via Disentangled Feature Augmentation `Nice` `NIPS` 
	> Train two networks: (1) learns bias features, (2) learns intrinsic features.
* Deep Learning on a Data Diet: Finding Important Examples Early in Training `NIPS` 
	> Grad and error ||y-\hat{y}|| norms can identify important examples. All experiments done on small datasets (CIFAR).
* Align before Fuse: Vision and Language Representation Learning with Momentum Distillation `SalesForce` `VLP`
* One Pass ImageNet `NIPS`  `Workshop`  
* Understanding Self-Supervised Learning Dynamics without Contrastive Pairs `ICML`
* Perceiver: General Perception with Iterative Attention `ICML`
* EfficientNetV2: Smaller Models and Faster Training `ICML`
	> progressively increase image-size + augmentation; replace DWConv at early layers with Fused-MBConv; add more layers to later stages (stage 5/6 in EfficientNet)
* Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision `ICML` `Google`
* Relative Positional Encoding for Transformers with Linear Complexity `ICML` `Transformers`  -- Tricky one
* Barlow Twins: Self-Supervised Learning via Redundancy Reduction `ICML`
* Self-training Improves Pre-training for Natural Language Understanding **#naacl2021**
* An interpretable classifier for high-resolution breast cancer screening images utilizing weakly supervised localization -- `NYU` **Medical image analysis**
* Robust breast cancer detection in mammography and digital breast tomosynthesis using an annotation-efficient -- `DeepHealth` **Nature Medicine**
* An improved mammography malignancy model with self-supervised learning -- `WR-AI` **SPIE Medical Imaging**
* MedAug: Contrastive learning leveraging patient metadata improves representations for chest X-ray interpretation -- `WR-AI` **MLHC2021**
* CSAW-M: An Ordinal Classification Dataset for Benchmarking Mammographic Masking of Cancer -- `KTH` **openreview2021**
* Evaluating Subgroup Disparity Using Epistemic Uncertainty In Mammography **#icml2021** `workshop`
* A Data Set and Deep Learning Algorithm for the Detection of Masses and Architectural Distortions in Digital Breast Tomosynthesis **#nlm2021** 
* Are Convolutional Neural Networks or Transformers more like human vision? **#CogSci2021**
* TorchIO: A Python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning **@ Computer Methods and Programs in Biomedicine** 
* Evaluation of deep learning-based artificial intelligence techniques for breast cancer detection on mammograms: Results from a retrospective study using a BreastScreen Victoria dataset `Medical`
* Toward robust mammography-based models for breast cancer risk `Medical` `Sci Transl Med` `Nice`
* Stand-Alone Use of Artificial Intelligence for Digital Mammography and Digital Breast Tomosynthesis Screening: A Retrospective Evaluation `RSNA` `Medical`
* PonderNet: Learning to Ponder `ICMLW`
* Is space-time attention all you need for video understanding? `ICML`
	> Train a divided temporal-spatial attention on top of 2d frame representations.
* Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples `IsoMax` `IEEE Neural Networks and Learning Systems`
* Public patient views of artificial intelligence in healthcare: A nominal group technique study `Medical` `Healthcare` `WR`
* Unifying vision-and-language tasks via text generation `VLP` `PMLR`
* Deep Transfer Learning for Multi-Source Entity Linkage via Domain Adaptation `AMZN` `EL` `VLDB`
* Image Composition Assessment with Saliency-augmented Multi-pattern Pooling `BMVC`
	> Evaluate image aesthetic using composition patterns
* [Receptance Weighted Key-Value] https://github.com/BlinkDL/RWKV-LM `Git`
	> followup on `Apple` Attention Free Transformer (AFT) 
* Medical Image Dataset Rebalancing via Conditional Deep Convolutional Generative Adversarial Networks (cDCGANs) `WR` `Stanford` `Intern`
	> Applications of conditional GANs in medical images.
* Trainable summarization to improve breast tomosynthesis classification. `MICCAI` `WR`
	> Temporal attention across slices before feeding into a classifier.
* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models `OpenAI`
	> Text-conditional diffusion model to OpenAI that beats GANs (DALI-E).