# Conflicting papers

`For every paper, there is a paper, equal in magnitude and opposite in direction` -- Ahmed Taha 2021


#### Grokking

* Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets
* Grokfast: Accelerated Grokking by Amplifying Slow Gradients


#### Smoothness

* Sharpness-Aware Minimization for Efficiently Improving Generalization
* Why is SAM Robust to Label Noise?

#### Generalization and memorization

* Understanding Deep Learning Requires Rethinking Generalization
* Explaining grokking through circuit efficiency


