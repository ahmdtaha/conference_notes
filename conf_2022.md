
## ICLR
* Understanding Dimensional Collapse in Contrastive Self-supervised Learning `FB AI`
	> Bad conclusion, but worth reading
* UniFormer: Unifying Convolution and Self-attention for Visual Recognition
	> Technicalities
* Fortuitous Forgetting in Connectionist Networks `Mila`
* VOS: Learning What You Don't Know by Virtual Outlier Synthesis `Uncertainty`
* Relational Surrogate Loss Learning
* The Uncanny Similarity of Recurrence and Depth `Nice`
* PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions
* Unsupervised Semantic Segmentation by Distilling Feature Correspondences
* BEiT: BERT Pre-Training of Image Transformers `Transformers` `Oral`
* iBOT: Image BERT Pre-Training with Online Tokenizer `SSL` `Nice`

## ECCV
* Contrastive Deep Supervision
	> Technicalities
* Frozen CLIP Models are Efficient Video Learners `Video` `Text`
	> Frozen CLIP frame features + light-weight temporal attention for short videos
* EclipSE: Efficient Long-range Video Retrieval using Sight and Sound `Video` `Text` `Audio`
	> Frozen CLIP frame features from long videos (V) + audio (A) features + (A2V) + (V2A) attention models

## CVPR
* Fine-tuning Image Transformers using Learnable Memory `Google` `Transformers` `Continual`
* QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection `Detection` `Technicalities`
* Delving Deep into the Generalization of Vision Transformers under Distribution Shifts `ViTs`
* SimMatch: Semi-supervised Learning with Similarity Matching `Technicalities`
* Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning `Oral` `Medical` `Transformers`
* When Does Contrastive Visual Representation Learning Work? `SSL`
* Vision-language pre-training with triple contrastive learning `ML` `SSL` `AMZN`
* Patch-level Representation Learning for Self-supervised Vision Transformers `SSL`
* What Makes Transfer Learning Work For Medical Images: Feature Reuse & Other Factors
	> Not convincing
* Multi-modal Alignment using Representation Codebook `AMZN` `VLP`
* Align and Prompt: Video-and-Language Pre-training with Entity Prompts `Sales` `VLP` `Video`
* Multiview Transformers for Video Recognition `Video` `Google` `Supervised`
* SimMIM: a Simple Framework for Masked Image Modeling `Image` `Microsoft` `Nice`
* Towards Total Recall in Industrial Anomaly Detection `AMZN`


## arXiv
* Self-supervised Learning from 100 Million Medical Images `Medical` `Siemens`
* A ConvNet for the 2020s
* OMNIVORE: A Single Model for Many Visual Modalities
* Vision Transformer for Small-Size Datasets
* Forgetting Data from Pre-trained GANs `KE` `GANs`
* Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision `Meta`
	> Brute force
* One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning `SSL` `NAS`
* When Does Re-initialization Work? `KE`
* Near Perfect GAN Inversion `AMZN` `GANs`
* The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon `KE` `Apple`
	> flings!
* What Knowledge Gets Distilled in Knowledge Distillation? `KD`
	> Nice Analysis
* High Fidelity Visualization of What Your Self-Supervised Representation Knows About `Meta` `SSL`
* Correct-n-Contrast: A Contrastive Approach for Improving Robustness to Spurious Correlations 
* A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments `Meta`
* Exploring Plain Vision Transformer Backbone for Object Detection `ViTDet`
* Text and Code Embeddings by Contrastive Pre-Training `OpenAI`
* Convolutional Xformers for Vision 
* ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest `ML`
* Robust and Efficient Medical Imaging with Self-Supervision `Google` `Medical`
* BEiT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers `Microsoft` `MIM`
* BEiT V3: Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks `Microsoft` `MIM`
* VLMO: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts `Microsoft` `MIM`
* VL-BEiT: Generative Vision-Language Pretraining `Microsoft` `MIM`
* CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment `Microsoft` `Video` `Text`
* Self-Supervised Learning for Videos: A Survey `SSL`
	> Needs revision
* LAVIS: A Library for Language-Vision Intelligence `Salesforce` `Nice`
* ERNIE-ViL 2.0: Multi-view Contrastive Learning for Image-Text Pre-training `Baidu` `Image` `Text`
* Mugs: A Multi-Granular Self-Supervised Learning Framework `Image` `SSL`
* Transcending Scaling Laws with 0.1% Extra Compute `NLP` `SSL`

## Generic
* Multi-Head Deep Metric Learning Using Global and Local Representations `WACV`
* When and how convolutional neural networks generalize to out-of-distribution categoryâ€“viewpoint combinations `Nature ML`
	> Nice analysis
* PVTv2: Improved Baselines with Pyramid Vision Transformer `CVMJ`
* GLaM: Efficient Scaling of Language Models with Mixture-of-Experts `ICML` `Google`
* Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time `ICML` `Google`
	> Nice analysis
* When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism `AAAI`
* A Random CNN Sees Objects: One Inductive Bias of CNN and Its Applications `AAAI`
* Towards Understanding Sharpness-Aware Minimization `ICML` `SAM`
* VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training `NIPS` `VLP` `Video`
* Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks
	> Did it before it is cool!