# arXiv
* Toolformer: Language Models Can Teach Themselves to Use Tools `Meta`
* ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders `Meta` `MAE`
* Language Is Not All You Need: Aligning Perception with Language Models `MultiModal` `LLM` `Microsoft`
* ViperGPT: Visual Inference via Python Execution for Reasoning `Nice`
	> High level **generic** reasoning system
* The effectiveness of MAE pre-pretraining for billion-scale pretraining `Meta`
* ActiveLab: Active Learning with Re-Labeling by Multiple Annotators
* Cut and Learn for Unsupervised Object Detection and Instance Segmentation `Meta` `Det` `Nice` `NCut`
	> Using normalized cuts to generate multiple masks, Conditional Random Field (CRF) to generate bboxes
* Segment Anything `Meta` `Seg`
* SAM Struggles in Concealed Scenes -- Empirical Study on "Segment Anything"
* Choose Your Weapon: Survival Strategies for Depressed AI Academics
	> Should read again
* DINOv2: Learning Robust Visual Features without Supervision
	> A lot of technical tricks to speed training and reduce memory
* Symbolic Discovery of Optimization Algorithms `Google`
	> LION optimizer using evolutionary algorithm (mutation, insertion, deleteion).


# Generic
* Dataset Distillation for Medical Dataset Sharing `AAAI` `Workshop` `DD`
* Conditional Positional Encodings for Vision Transformers `ICLR` `ViT`
	> relative positional embedding with latent absolute positional information (zero-padding)
* On the duality between contrastive and non-contrastive self-supervised learning `ICLR`
	> sample contrastive vs. dimension contrastive. Revise assumptions about batch-size and embedding dimension
	
# CVPR
* MVImgNet: A Large-scale Dataset of Multi-view Images `Dataset`
* Simulated Annealing in Early Layers Leads to Better Generalization `KE` `LLF` `Mila`
* Slide-Transformer: Hierarchical Vision Transformer with Local Self-Attention
	> Efficient Local attention at early layers and regular global attention at late layers