# Interesting ICCV2019 papers
> and my superficial opinion -- just one scan

### Retrieval / Space Embedding #retrieval
* Unconstrained Foreground Object Search -- :hash:industry :hash:Adobe 

 >looks similar to "Compositing-aware image search", maybe different sampling approach
* Deep Meta Metric Learning 
* Attention-Aware Polarity Sensitive Embedding for Affective Image Retrieval
* Personalized Fashion Design
> Interesting way to learn user preference representation

* Ground-to-Aerial Image Geo-Localization With a Hard Exemplar Reweighting Triplet Loss
> Problem is interesting but naive triplet re-weighting. Datasets used CVUSA and  VH.
* Zero-Shot Emotion Recognition via Affective Structural Embedding
* Learning Similarity Conditions Without Explicit Supervision
> Interesting problem but the solution is not convincing
* Towards Latent Attribute Discovery From Triplet Similarities
> Instead of dividing the embedding into k sub-embedding, This paper learns masks per attribute in unsupervised. CSN is supervised.
* HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips — **dataset**
* Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings
> Nice paper to review, not sure why contrastive loss outperform triplet loss! The paper uses 256x256 images while other papers uses 227x227 like [Hardness-aware deep metric learning]
* Image Aesthetic Assessment Based on Pairwise Comparison – A Unified Approach to Score Regression, Binary Classification, and Personalization -- **Regression**
* Universal Perturbation Attack Against Image Retrieval
* CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval
* Invariant Information Clustering for Unsupervised Image Classification and Segmentation
> Nice Paper
* Learning with Average Precision: Training Image Retrieval with a Listwise Loss
> Nice re-formulation of histogram loss. While the proposal is technically costly, it will be cheaper in the future.
* SoftTriple Loss: Deep Metric Learning Without Triplet Sampling
* Deep Metric Learning with Tuplet Margin Loss
* Learning Local Descriptors With a CDF-Based Dynamic Soft Margin
> Nicely written, reminds me of histogram loss. did not check the binary descriptor part.
* No Fear of the Dark: Image Retrieval under Varying Illumination Conditions
* Unsupervised Neural Quantization for Compressed-Domain Similarity Search
* Better and Faster: Exponential Loss for Image Patch Matching
* Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval -- product quantization.

### Self/Un Supervised learning 

* S4L: Self-Supervised Semi-Supervised Learning
> Nice review for Self-Supervised Semi-Supervised learning approaches

* SVD: A Large-Scale Short Video Dataset for Near-Duplicate Video Retrieval **dataset**
* Local Aggregation for Unsupervised Learning of Visual Embeddings **#ranking**

* Unsupervised Pre-Training of Image Features on Non-Curated Data — :hash:industry :hash:Facebook 
> Curated vs uncurated dataset

* Dual Student: Breaking the Limits of the Teacher in Semi-supervised Learning -- SSL - Need to read >Temporal ensembling for semisupervised learning

* Self-Supervised Representation Learning via Neighborhood-Relational Encoding
> Interesting idea, poorly written

* Semi-supervised Skin Detection by Network with Mutual Guidance
> Technicalities -- New skin dataset

* Scaling and Benchmarking Self-Supervised Visual Representation Learning — :hash:industry :hash:Facebook
> Nice review -- a lot of experiments

* Stochastic Attraction-Repulsion Embedding for Large Scale Image Localization
> Yet another ranking loss

### Zero/Few Shot learning 

* Zero-Shot Grounding of Objects from Natural Language Queries -- technicalities
* Modeling Inter and Intra-Class Relations in the Triplet Loss for Zero-Shot Learning **#ranking**
* Learning Feature-to-Feature Translator by Alternating Back-Propagation for Generative Zero-Shot Learning

### Attention 
* Understanding Deep Networks via Extremal Perturbations and Smooth Masks 

> Better Reformulating of Interpretable explanations of black boxes by meaningful perturbation

### NAS
* Exploring Randomly Wired Neural Networks for Image Recognition — :hash:industry :hash:Facebook

### Adversarial Learning

* Adversarial Learning with Margin-based Triplet Embedding Regularization

> Regularize the space embedding similar to "Boosting Standard Classification Architectures Through a Ranking Regularizer".

### Distillation
* Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation

* On the Efficacy of Knowledge Distillation
> Simple solution but a better solution exists? -- Feels similar to [1]

* Similarity-Preserving Knowledge Distillation
* Correlation Congruence for Knowledge Distillation -- Nice paper

### Noisy Labels
* Deep Self-Learning From Noisy Labels -- simple but too many hyperparameters.

### Misc
* Co-Separating Sounds of Visual Objects — :hash:industry :hash:Facebook 
* Class-balanced loss based on effective number of samples — :hash:industry :hash:Google
* Sampling-Free Epistemic Uncertainty Estimation Using Approximated Variance Propagation -- uncertainty without MC
* Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval -- product quantization

* [1] Human uncertainty makes classification more robust
> Valid hypothesis but very expensive

* Incremental classifier and representation learning.
> Technicalities