# Interesting CVPR2020 papers
> and my superficial opinion -- just one scan

### Classification & Recognition
* Don’t Judge an Object by Its Context: Learning to Overcome Contextual Bias
	> `PI_Reading_Grp` :hash:industry :hash:FB AI


### Embedding
* Fashion Outfit Complementary Item Retrieval
	> lsd, :hash:industry :hash:amazon

* Image Search with Text Feedback by Visiolinguistic Attention Learning
	> Technicalities	:hash:industry :hash:amazon
* Which is Plagiarism: Fashion Image Retrieval based on Regional Representation for Design Protection
	> Industry	

* Cross-Batch Memory for Embedding Learning
	> Nice!

* Proxy Anchor Loss for Deep Metric Learning
	>Proxy-NCA + Lifted Structuered; converges faster

* Moving in the Right Direction: A Regularization for Deep Metric Learning 
	> Angular loss combined with triplet loss

* Embedding Expansion: Augmentation in Embedding Space for Deep Metric Learning 
* Uninformed Students: Student–Teacher Anomaly Detection with Discriminative Latent Embeddings 
	> Nice anomaly detection application for feature embedding

* Circle Loss: A Unified Perspective of Pair Similarity Optimization 
	> Dynamic similarity weighting (similar to weighting samples hard/easy)

* Searching for Actions on the Hyperbole
	> The idea is simple and valid, but how actions are embedded? where does \phi_c(k) in eq. 10 comes from?
	
* Hyperbolic Image Embeddings
	> Interesting!
	
* RankMI: A Mutual Information Maximizing Ranking Loss
	> Interesting!	
	
* Sketch Less for More: On-the-Fly Fine-Grained Sketch Based Image Retrieval 
	> Nice RL formulation
	
* Deep Metric Learning via Adaptive Learnable Assessment
	> Nice but I think it is expensive to train the Assessor (Meta-Learning) part

* Context-Aware Attention Network for Image-Text Retrieval
	> Slow ?
	
* Central Similarity Quantization for Efficient Image and Video Retrieval 
	> Easy to read quantization paper
	
### knowledge Distillation
* Regularizing Class-wise Predictions via Self-knowledge Distillation
	> Simple and seems to be working

* Revisiting Knowledge Distillation via Label Smoothing Regularization
	> A network should never be over-confident about it output
* Self-training with Noisy Student improves ImageNet classification 
	> !!
* Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion
	> Simple regularization approach to generate better images. Interesting experiments. :hash:industry :hash:Nvidia
* Online Knowledge Distillation via Collaborative Learning 
	> Simple	
* Distilling Cross-Task Knowledge via Relationship Matching 
	> Eq. 5 & 6	

### Unsupervised/Self-supervised Learning

* Large Scale Video Representation Learning via Relational Graph Clustering 
	> Technicalities for large video datasets - :hash:industry :hash:google research

* Online Deep Clustering for Unsupervised Representation Learning 
* Steering Self-Supervised Feature Learning Beyond Local Pixel Statistics
	> `PI_Reading_Grp` :hash:industry :hash:Adobe
* Same Features, Different Day: Weakly Supervised Feature Learning for Seasonal Invariance 
	> Interesting
* Unsupervised Learning from Video with Deep Neural Embeddings 
* Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-Supervision
* SpeedNet: Learning the Speediness in Videos
	> `PI_Reading_Grp` :hash:industry :hash:Google Well-written paper , related to the following papers
* OOPS: Predicting Unintentional Action in Video 
* Video Playback Rate Perception for Self-supervised Spatio-Temporal Representation Learning
	> Technicalities
	



### Representation Learning
* Self-Supervised Learning of Pretext-Invariant Representations
	> Self-Supervised Representation Learning by Rotation Feature Decoupling
	> 
	> Mathematical notation! :hash:industry :hash:FB - AI Research

* ClusterFit: Improving Generalization of Visual Representations 
	> Deep Clustering for Unsupervised Learning of Visual Features :hash:industry :hash:FB - AI

* Evolving Losses for Unsupervised Video Representation Learning 
	> I should read more about evolutionary algorithm :hash:industry :hash:google research
	
* Towards Backward-Compatible Representation Learning 
	> Enforce backward-compatible by fixing the classifier weights (fix the old class/identity centers) :hash:industry :hash:Amazon

* End-to-End Learning of Visual Representations from Uncurated Instructional Videos 
	> Simple trick
	
* Learning Representations by Predicting Bags of Visual Words 
	> Interesting discretization for the image space

* How Useful is Self-Supervised Pretraining for Visual Tasks?
	> No wonder "Why Does Unsupervised Pre-training Help Deep Learning?" is not cited.
	
* Deep Representation Learning on Long-tailed Data: A Learnable Embedding Augmentation Perspective
	> Simple feature embedding trick for imbalance datasets.
	
### GANs
* CNN-generated images are surprisingly easy to spot... for now -- `PI_Reading_Grp`
* PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models 
	> Looks complex but actually simple
* Unpaired Image Super-Resolution using Pseudo-Supervision
* Image Synthesis with Semantic Region-Adaptive Normalization -- `PI_Reading_Grp`


### Adversarial & Model-Inversion Attacks
* The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural --  `PI_Reading_Grp`
* Hierarchically Robust Representation Learning

### Math-Based
* Computing the Testing Error without a Testing Set 
	> Interesting
* Adaptive Subspaces for Few-Shot Learning -- `PI_Reading_Grp`

### Few/Zero-shot learning

* Boosting Few-Shot Learning With Adaptive Margin Loss
	> No inspection for the learned margins!, the scale parameter \alpha is assumed to be positive, Why?

### Datasets
* Google __Landmarks__ Dataset v2 A Large-Scale Benchmark for Instance-Level Recognition and Retrieval
* Scalability in Perception for __Autonomous Driving__: Waymo Open Dataset
* Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics  -- Nice review
* FineGym: A Hierarchical Video Dataset for **Fine-grained Action Understanding** 



### Misc
* Self2Self With Dropout: Learning Self-Supervised Denoising From Single Image 
	> Simple trick to create I/O pairs from single image, use "dropout as bayesian" to minimize variance in output

* SaccadeNet: A Fast and Accurate Object Detector 
	> Object detection -- `PI_Reading_Grp`
* SuperGlue: Learning Feature Matching with Graph Neural Networks
	> Nice new formulation for feature/point correspondence  -- `PI_Reading_Grp`
* Unsupervised **Domain Adaptation** via Structurally Regularized Deep Clustering  -- `PI_Reading_Grp` 
* Overcoming Classifier Imbalance for Long-tail Object Detection with Balanced Group Softmax
	> `PI_Reading_Grp` imbalance dataset


	