# Interesting CVPR2021 papers
> and my superficial opinion -- just one scan


### Metric Learning
* SLADE: A Self-Training Framework For Distance Metric Learning
	> LSD	Self-supervised pretraining beats ImageNet + Sample unlabeled data using similarity distribution loss. lsd :hash:industry :hash:amazon
* Efficient Object Embedding for Spliced Image Retrieval
	> LSD	:hash:industry :hash:facebook
* knowledge Evolution Neural Networks
	> Mine :) "Classification, Small datasets"
* Unsupervised Discovery of the Long-Tail in Instance Segmentation Using Hierarchical Self-Supervision
	> I should try this hyperbolic embeddings
* Embedding Transfer with Label Relaxation for Improved Metric Learning
	> Now, we have to train two models for metric learning
* Dynamic Metric Learning: Towards a Scalable Metric Space to Accommodate Multiple Semantic Scales
	> Multiple margin hyperparameters

### Representation Learning / Self/Un-supervised learning
* Jigsaw Clustering for Unsupervised Visual Representation Learning
	> Seems like clustering is doing all the heavy work.
* Playable Video Generation -- `PI_arXiv_Ch` 
	> Too many loss terms
* Representation Learning via Global Temporal Alignment and Cycle-Consistency -- `PI_arXiv_Ch` 
	> Differentiable time-warping for videos
* Read and Attend: Temporal Localisation in Sign Language Videos
	> assume access to a sparse collection of annotation. Use Transformer attention to localize actions in videos!
* Unsupervised Visual Representation Learning by Tracking Patches in Video 

### Architecture Design
* RepVGG: Making VGG-style ConvNets Great Again -- `PI_arXiv_Ch`


### Zero/Few-shot learning
* Open World Compositional Zero-Shot Learning
	> zero-shot formulated as metric learning problem
	
### GANs
* DatasetGAN: Efficient Labeled Data Factory with Minimal Human Effort

### Incremental/Continual Learning
* IIRC: Incremental Implicitly-Refined Classification
* DER: Dynamically Expandable Representation for Class Incremental Learning 


### Misc
* The Affective Growth of Computer Vision
	> Nice reading but worried about the selection bais in informants.
* InverseForm: A Loss Function for Structured Boundary-Aware Segmentation
	> Segmentation
* On Feature Normalization and Data Augmentation
	> data augmentation techniques